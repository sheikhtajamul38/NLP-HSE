{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWH34qM2HKMK",
        "outputId": "995718b2-9b2c-46fe-9cc4-d8ad36627b08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/cuda/__init__.py:497: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2023-03-04 20:33:04.806824: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-04 20:33:04.806983: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
            "2023-03-04 20:33:04.807010: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-04 20:33:07.463292: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-md==3.4.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.4.1/en_core_web_md-3.4.1-py3-none-any.whl (42.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.5.0,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from en-core-web-md==3.4.1) (3.4.4)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.0.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.10.5)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.3.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.0.9)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (4.64.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.0.12)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (57.4.0)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.10.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.10.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.4.6)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (8.1.7)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.25.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.1.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.22.4)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (3.0.8)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.0.7)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.8/dist-packages (from spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (6.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (1.26.14)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.10)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.8/dist-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.8/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->spacy<3.5.0,>=3.4.0->en-core-web-md==3.4.1) (2.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "from spacy.matcher import Matcher \n",
        "import json\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import random\n",
        "import string\n",
        "from spacy import displacy\n",
        "!python -m spacy download en_core_web_md"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twANYUk_THWC",
        "outputId": "6b1a7945-beb3-42ed-963b-a72563c8fa99"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = pd.read_csv('dataset.csv',names = ['intents','extents'])\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "iH5Ww5bdHK9Q",
        "outputId": "43a71538-fcfd-4c22-f63d-b129aebb2ff3"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            intents                                            extents\n",
              "0       atis_flight   i want to fly from boston at 838 am and arriv...\n",
              "1       atis_flight   what flights are available from pittsburgh to...\n",
              "2  atis_flight_time   what is the arrival time in san francisco for...\n",
              "3      atis_airfare            cheapest airfare from tacoma to orlando\n",
              "4      atis_airfare   round trip fares from pittsburgh to philadelp..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cfc13e5e-eb5d-4e83-ba10-07fad17ecfc9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>intents</th>\n",
              "      <th>extents</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>atis_flight</td>\n",
              "      <td>i want to fly from boston at 838 am and arriv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>atis_flight</td>\n",
              "      <td>what flights are available from pittsburgh to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>atis_flight_time</td>\n",
              "      <td>what is the arrival time in san francisco for...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>atis_airfare</td>\n",
              "      <td>cheapest airfare from tacoma to orlando</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>atis_airfare</td>\n",
              "      <td>round trip fares from pittsburgh to philadelp...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cfc13e5e-eb5d-4e83-ba10-07fad17ecfc9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cfc13e5e-eb5d-4e83-ba10-07fad17ecfc9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cfc13e5e-eb5d-4e83-ba10-07fad17ecfc9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"en_core_web_md\")"
      ],
      "metadata": {
        "id": "29gp_L2VHRF0"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_entities(pipe,text):\n",
        "  doc = pipe(text)\n",
        "  entities = {}\n",
        "  for entity in doc.ents:\n",
        "    if entity.label_ not in entities:\n",
        "\n",
        "      entities[entity.label_] = [entity.text]\n",
        "    else:\n",
        "      entities[entity.label_] += [entity.text]\n",
        "  # Show entities in pretty manner\n",
        "  displacy.render(doc, jupyter=True, style='ent')\n",
        "  return entities\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "text = \"\"\"i want to fly from boston at 838 am and arrive in denver at 1110 in the morning\"\"\"\n",
        "text = \"show the flights from pittsburgh to san francisco again on monday\"\n",
        "ents = get_entities(nlp, text)\n",
        "print(ents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "1mMFSGR8HTni",
        "outputId": "f2659b50-1c03-466f-e18a-099a0d124a1b"
      },
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">show the flights from \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    pittsburgh\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " to \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    san francisco\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " again on \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    monday\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              "</div></span>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'GPE': ['pittsburgh', 'san francisco'], 'DATE': ['monday']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parsed_sentence = nlp(text)\n",
        "lis = [token.text for token in parsed_sentence]\n",
        "print(lis)\n",
        "entities = {}\n",
        "for entity in parsed_sentence.ents:\n",
        "  if entity.label_ not in entities:\n",
        "    if entity.label_ == 'GPE':\n",
        "      loc = entity.text\n",
        "      loc = loc.split(' ')\n",
        "      if len(loc)>1:\n",
        "        id = lis.index(loc[0])\n",
        "      else:\n",
        "\n",
        "        id = lis.index(entity.text)\n",
        "      print(id)\n",
        "      entities[entity.label_] = [lis[id-1]+' '+entity.text]\n",
        "  else:\n",
        "    if entity.label_ == 'GPE':\n",
        "      loc = entity.text\n",
        "      loc = loc.split(' ')\n",
        "      if len(loc)>1:\n",
        "        id = lis.index(loc[0])\n",
        "      else:\n",
        "\n",
        "        id = lis.index(entity.text)\n",
        "      #id = lis.index(entity.text)\n",
        "      entities[entity.label_] += [lis[id-1]+' '+entity.text]\n",
        "entities"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsEDD1zNIXwg",
        "outputId": "76e047e9-6026-4134-d918-5bf42c7102b7"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['show', 'the', 'flights', 'from', 'pittsburgh', 'to', 'san', 'francisco', 'again', 'on', 'monday']\n",
            "4\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'GPE': ['from pittsburgh', 'to san francisco']}"
            ]
          },
          "metadata": {},
          "execution_count": 204
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def locations(gpe):\n",
        "  for i in list(entities.keys()):\n",
        "    if i=='GPE':\n",
        "      x = entities[i]\n",
        "      if len(x)>1:\n",
        "        for j in x:\n",
        "          loc = j.split(' ')\n",
        "          if type(entities[i]) is not dict:\n",
        "            entities[i]={}\n",
        "            entities[i][loc[0]] = loc[1:]\n",
        "          else:\n",
        "            entities[i][loc[0]] = loc[1:]\n",
        "\n",
        "  return entities"
      ],
      "metadata": {
        "id": "sxI0WJZcHgGe"
      },
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entities = locations(entities)\n",
        "entities['locations'] = entities.pop('GPE')\n",
        "entities"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYFVGCbIHphJ",
        "outputId": "75b3d034-d731-4bb8-8b2c-511c31e8b4a4"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'locations': {'from': ['pittsburgh'], 'to': ['san', 'francisco']}}"
            ]
          },
          "metadata": {},
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ents['locations'] = entities['locations']\n",
        "ents.pop('GPE')\n",
        "ents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHv4Du_IHwg8",
        "outputId": "5d86c7ee-6894-494b-b82f-2f9e54e97838"
      },
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'DATE': ['monday'],\n",
              " 'locations': {'from': ['pittsburgh'], 'to': ['san', 'francisco']}}"
            ]
          },
          "metadata": {},
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9ImhSU8VJGhw"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Intents"
      ],
      "metadata": {
        "id": "H5_ScUuZJotM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Method 1 for finding intents\n",
        "#Use root + dobj to find intents\n",
        "def semantic_parsing(request):\n",
        "  doc = nlp(request)\n",
        "  intent = ''\n",
        "  for token in doc:\n",
        "    if token.dep_ ==\"dobj\":\n",
        "      intent = token.head.lemma_ + token.lemma_.capitalize()\n",
        "  #if dobj is not present return 'NoIntentFound'\n",
        "  if len(intent)>0:\n",
        "    return intent\n",
        "  else:\n",
        "    return 0\n",
        "intent = semantic_parsing(text)\n",
        "print(intent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruxsAzlUJprn",
        "outputId": "aa0752f2-f2c3-43b6-8d81-1b62c7e75b17"
      },
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "showFlight\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#using traing data for finding verb dobj and nsubj\n",
        "train = df.sample(frac=0.7, random_state=42)\n"
      ],
      "metadata": {
        "id": "I_BVDL35KYQa"
      },
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#removing the atis from intents \n",
        "intents = list(train['intents'])\n",
        "ints= []\n",
        "for i in intents:\n",
        "  ints.append(i[5:])\n",
        "temp = []\n",
        "# removing duplicates via Naive Method\n",
        "for element in ints:\n",
        "  elem = str(element)\n",
        "  if '#' in elem:\n",
        "    pass\n",
        "  elif(elem not in temp):\n",
        "    temp.append(str(element))\n",
        "temp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hk-IhNzXNDBI",
        "outputId": "996e4a98-bab5-4c83-b7ba-fa107b287b01"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['flight',\n",
              " 'airfare',\n",
              " 'airport',\n",
              " 'aircraft',\n",
              " 'ground_service',\n",
              " 'airline',\n",
              " 'flight_no',\n",
              " 'distance',\n",
              " 'abbreviation',\n",
              " 'capacity',\n",
              " 'quantity',\n",
              " 'city',\n",
              " 'flight_time',\n",
              " 'restriction',\n",
              " 'meal',\n",
              " 'ground_fare',\n",
              " 'cheapest']"
            ]
          },
          "metadata": {},
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#extracting all the first dobj's that exist in out dataset\n",
        "def get_dobj(uterence):\n",
        "  objs = {}\n",
        "  for i in uterence:\n",
        "    doc = nlp(i)\n",
        "    for token in doc:\n",
        "      if token.dep_ =='dobj':\n",
        "        if token.text not in objs:\n",
        "          objs[token.text] = 1\n",
        "        else:\n",
        "          objs[token.text] += 1\n",
        "        break\n",
        "  dobjs = dict(sorted(objs.items(), key=lambda item: item[1],reverse=True))\n",
        "  dobj = tuple(dobjs.keys())\n",
        "  dsubs = []\n",
        "  for i in dobj:\n",
        "    if len(i)>3:\n",
        "      dsubs.append(i)\n",
        "    else:\n",
        "      pass\n",
        "  dsubs = tuple(dsubs)\n",
        "  return dsubs"
      ],
      "metadata": {
        "id": "osdwYWF3NmoK"
      },
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#extracting all the first verb that exist in out dataset\n",
        "def get_tverb(uterence):\n",
        "  verbs = {}\n",
        "  for i in uterence:\n",
        "    doc = nlp(i)\n",
        "    for token in doc:\n",
        "      if token.pos_ =='VERB':\n",
        "        if token.text not in verbs:\n",
        "          verbs[token.text] = 1\n",
        "        else:\n",
        "          verbs[token.text] += 1\n",
        "        break\n",
        "  tverbs = dict(sorted(verbs.items(), key=lambda item: item[1],reverse=True))\n",
        "  nsubj = tuple(tverbs.keys())\n",
        "  nsubs = []\n",
        "  for i in nsubj:\n",
        "    if len(i)>3:\n",
        "      nsubs.append(i)\n",
        "    else:\n",
        "      pass\n",
        "  tverb = tuple(nsubs)\n",
        "  return tverb"
      ],
      "metadata": {
        "id": "OuXKEwwxOJZj"
      },
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#extracting all the first nsubj's that exist in out dataset\n",
        "def get_nsub(uterence):\n",
        "  sub = {}\n",
        "  for i in uterence:\n",
        "    doc = nlp(i)\n",
        "    for token in doc:\n",
        "      if token.dep_ =='nsubj':\n",
        "        if token.text not in sub:\n",
        "          sub[token.text] = 1\n",
        "        else:\n",
        "          sub[token.text] += 1\n",
        "        break\n",
        "\n",
        "  nsubs = dict(sorted(sub.items(), key=lambda item: item[1],reverse=True))\n",
        "  nsubj = tuple(nsubs.keys())\n",
        "  nsubs = []\n",
        "  for i in nsubj:\n",
        "    if len(i)>3:\n",
        "      nsubs.append(i)\n",
        "    else:\n",
        "      pass\n",
        "  nsubs = tuple(nsubs)\n",
        "  return nsubs"
      ],
      "metadata": {
        "id": "8CqSv76nOJrK"
      },
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#storing verb+nsubj+dobj as wordlist\n",
        "utterences = list(df['extents'])\n",
        "nsubs,objs,verbs = get_nsub(utterences),get_dobj(utterences),get_tverb(utterences)\n",
        "nsubs[:10],objs[:10],verbs[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twevOSEQOMMS",
        "outputId": "58ebf84f-4c2c-4da3-aab6-6821329dc71e"
      },
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(('flights',\n",
              "  'what',\n",
              "  'that',\n",
              "  'flight',\n",
              "  'airlines',\n",
              "  'which',\n",
              "  'transportation',\n",
              "  'fare',\n",
              "  'fares',\n",
              "  'airline'),\n",
              " ('flights',\n",
              "  'flight',\n",
              "  'what',\n",
              "  'information',\n",
              "  'fares',\n",
              "  'airlines',\n",
              "  'fare',\n",
              "  'list',\n",
              "  'transportation',\n",
              "  'which'),\n",
              " ('show',\n",
              "  'like',\n",
              "  'need',\n",
              "  'list',\n",
              "  'give',\n",
              "  'want',\n",
              "  'have',\n",
              "  'leaving',\n",
              "  'philadelphia',\n",
              "  'find'))"
            ]
          },
          "metadata": {},
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "objs= objs+tuple(temp)"
      ],
      "metadata": {
        "id": "rM0969TkYdA2"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Method 2\n",
        "def parse(text,objs,verbs):\n",
        "  doc = nlp(text)\n",
        "  dObj =None\n",
        "  tVerb = None\n",
        "  # Extract the direct object and its transitive verb\n",
        "  for token in doc:\n",
        "    if token.dep_ == \"dobj\":\n",
        "      dObj = token\n",
        "      tVerb = token.head\n",
        "  # Extract the helper verb\n",
        "  intentVerb = None\n",
        "  verbList = verbs\n",
        "  if tVerb.text in verbList:\n",
        "    intentVerb = tVerb\n",
        "  else:\n",
        "    if tVerb.head.dep_ == \"ROOT\":\n",
        "      helperVerb = tVerb.head\n",
        "  # Extract the object of the intent\n",
        "  intentObj = None\n",
        "  objList = objs\n",
        "  if dObj.text in objList:\n",
        "    intentObj = dObj\n",
        "  else:\n",
        "    for child in dObj.children:\n",
        "      if child.dep_ == \"prep\":\n",
        "        intentObj = list(child.children)[0]\n",
        "        break\n",
        "      elif child.dep_ == \"compound\":\n",
        "        intentObj = child\n",
        "        break\n",
        "  if intentVerb == None or intentObj ==None:\n",
        "    return 0\n",
        "  else:\n",
        "\n",
        "    intent = intentVerb.text + intentObj.text.capitalize()\n",
        "    return intent\n",
        "result2 = parse(text,objs, verbs)\n",
        "print(result2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FezAxihPL-q",
        "outputId": "d15aea17-44fa-4233-eb58-3789bb325632"
      },
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "showFlights\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Finsing synonyms of all the verb, subj and object and storing as tuples in a list\n",
        "def get_some_word_synonyms(word):\n",
        "    word = word.lower()\n",
        "    synonyms = []\n",
        "    synsets = wordnet.synsets(word)\n",
        "    if (len(synsets) == 0):\n",
        "        return []\n",
        "    synset = synsets[0]\n",
        "    lemma_names = synset.lemma_names()\n",
        "    for lemma_name in lemma_names:\n",
        "        lemma_name = lemma_name.lower().replace('_', ' ')\n",
        "        if (lemma_name != word and lemma_name not in synonyms):\n",
        "            synonyms.append(lemma_name)\n",
        "    return synonyms\n",
        "def get_all_word_synonyms(word):\n",
        "    word = word.lower()\n",
        "    synonyms = []\n",
        "    synsets = wordnet.synsets(word)\n",
        "    if (len(synsets) == 0):\n",
        "        return []\n",
        "    for synset in synsets:\n",
        "        lemma_names = synset.lemma_names()\n",
        "        for lemma_name in lemma_names:\n",
        "            lemma_name = lemma_name.lower().replace('_', ' ')\n",
        "            if (lemma_name != word and lemma_name not in synonyms):\n",
        "                synonyms.append(lemma_name)\n",
        "    return synonyms\n",
        "def make_synonyms(lists):\n",
        "  syns = []\n",
        "  ob = []\n",
        "  for word in lists:\n",
        "      synonyms = get_all_word_synonyms(word)\n",
        "      for synonym in synonyms:\n",
        "          syns.append(synonym)\n",
        "      ob.append(tuple(syns))\n",
        "      syns = []\n",
        "  return ob"
      ],
      "metadata": {
        "id": "MFjoTM1SRHFN"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "from nltk.corpus import sentiwordnet as swn, wordnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqLrGJkFUDr8",
        "outputId": "4968eb3a-3527-48f8-f937-54a80f0871ac"
      },
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ver_syn,obj_syn,sub_sun = make_synonyms(verbs),make_synonyms(objs),make_synonyms(nsubs) \n",
        "ver_syn[:2],obj_syn[:2],sub_sun[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dh2iUbrSL42",
        "outputId": "d6e5eecc-f636-4b76-da43-17ee09c4bf59"
      },
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([('display',\n",
              "   'appearance',\n",
              "   'demo',\n",
              "   'exhibit',\n",
              "   'present',\n",
              "   'demonstrate',\n",
              "   'prove',\n",
              "   'establish',\n",
              "   'shew',\n",
              "   'testify',\n",
              "   'bear witness',\n",
              "   'evidence',\n",
              "   'picture',\n",
              "   'depict',\n",
              "   'render',\n",
              "   'express',\n",
              "   'evince',\n",
              "   'indicate',\n",
              "   'point',\n",
              "   'designate',\n",
              "   'show up',\n",
              "   'read',\n",
              "   'register',\n",
              "   'record',\n",
              "   'usher'),\n",
              "  ('the like',\n",
              "   'the likes of',\n",
              "   'ilk',\n",
              "   'wish',\n",
              "   'care',\n",
              "   'similar',\n",
              "   'same',\n",
              "   'alike',\n",
              "   'comparable',\n",
              "   'corresponding')],\n",
              " [('flight',\n",
              "   'flying',\n",
              "   'flight of stairs',\n",
              "   'flight of steps',\n",
              "   'escape',\n",
              "   'trajectory',\n",
              "   'fledge'),\n",
              "  ('flying',\n",
              "   'flight of stairs',\n",
              "   'flight of steps',\n",
              "   'escape',\n",
              "   'trajectory',\n",
              "   'fledge')],\n",
              " [('flight',\n",
              "   'flying',\n",
              "   'flight of stairs',\n",
              "   'flight of steps',\n",
              "   'escape',\n",
              "   'trajectory',\n",
              "   'fledge'),\n",
              "  ()])"
            ]
          },
          "metadata": {},
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def semantic_parsing(text,obj_syn,ver_syn):\n",
        "  doc = nlp(text)\n",
        "  intents = []\n",
        "  transVerbs = ver_syn\n",
        "  directObjs = obj_syn\n",
        "  for sent in doc.sents:\n",
        "    tverb = ''\n",
        "    dobj = ''\n",
        "    intent = ''\n",
        "    for token in sent:\n",
        "      if token.dep_ == 'dobj':\n",
        "        tverb = token.head.text \n",
        "        dobj = token.text\n",
        "    \n",
        "    verbSyns = [tpl for tpl in transVerbs if tverb in tpl]\n",
        "    dobjSyns = [tp for tp in directObjs if dobj in tp]\n",
        "    if dobjSyns == []:\n",
        "      intent = verbSyns[0][0].capitalize() +'_' + dobj\n",
        "    elif verbSyns != [] and dobjSyns != []: \n",
        "      intent = verbSyns[0][0].capitalize() +'_' + dobjSyns[0][0].capitalize()\n",
        "    if intent != '':\n",
        "      intents.append(tuple((sent.text.rstrip(), intent)))\n",
        "  return intents\n",
        "result = semantic_parsing(text,obj_syn,ver_syn)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aALpP6XTBIL",
        "outputId": "e6e8d5ec-f80c-4061-e4de-d7285ffc1bd2"
      },
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('show the flights from pittsburgh to san francisco again on monday', 'Show_flights')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final = {}\n",
        "final['utterence'] = str(text)\n",
        "final['intent'] = intent\n",
        "final['entities'] = ents\n",
        "final"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZLRlr_kUxyg",
        "outputId": "28cc0d43-c458-4f25-913a-3896fd566ec5"
      },
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'utterence': 'show the flights from pittsburgh to san francisco again on monday',\n",
              " 'intent': 'showFlight',\n",
              " 'entities': {'DATE': ['monday'],\n",
              "  'locations': {'from': ['pittsburgh'], 'to': ['san', 'francisco']}}}"
            ]
          },
          "metadata": {},
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jss = json.dumps(final, ensure_ascii=False, indent=4)\n",
        "print(jss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ch-vAmJ3Vts2",
        "outputId": "c20ee8ec-3898-4057-e7e9-2dbbe24c08ad"
      },
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"utterence\": \"show the flights from pittsburgh to san francisco again on monday\",\n",
            "    \"intent\": \"showFlight\",\n",
            "    \"entities\": {\n",
            "        \"DATE\": [\n",
            "            \"monday\"\n",
            "        ],\n",
            "        \"locations\": {\n",
            "            \"from\": [\n",
            "                \"pittsburgh\"\n",
            "            ],\n",
            "            \"to\": [\n",
            "                \"san\",\n",
            "                \"francisco\"\n",
            "            ]\n",
            "        }\n",
            "    }\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZhQ0x2qMY16B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}