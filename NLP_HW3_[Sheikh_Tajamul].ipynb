{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "6xkRMqKIN_m4",
        "wARGtO4ZCRdD",
        "v8YEHtL4CX3_",
        "MkwVI8QXB0hx",
        "U9WAqGn8Bhs-",
        "_eMjY4zUBTqa",
        "tNyw3acJDSvX",
        "z6bDXq0NDY29",
        "l4R6_qYFDakO",
        "DBnQPr5FDcZh",
        "_63Amv25PkkA"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#This Notebook is part of a homework assignment in NLP on an ATIS Dataset\n",
        "###Different Types of models were implemented to perform the text classification of intenets on the given dataset\n",
        "\n",
        "\n",
        "1.   Machine learning based models like logistic regression, NaiveBayesClassifier and SVM were implemented\n",
        "2.   Two Rule based models were implemented to classify the intents, one was implemented on whole dataset and another one on top 8 most occuring intents\n",
        "3.   Neural network and DNN models were also implemented as part of this homework.\n",
        "\n",
        "At the end of the notebook, accuracy of all the models were compared.\n",
        "\n"
      ],
      "metadata": {
        "id": "6xkRMqKIN_m4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isRqV2YbyIio"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/PacktPublishing/Mastering-spaCy/main/Chapter06/data/atis_intents.csv\")\n",
        "\n",
        "df.columns = ['intent', 'utterance']\n",
        "df.head()\n",
        "log = pd.DataFrame(columns=['model','accuracy'])\n",
        "res,acc = [],[]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGbRUixcCPVZ",
        "outputId": "7f78b055-92df-4c3e-a5a3-273796689752"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.9/dist-packages (3.8.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk) (2022.10.31)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk) (1.1.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk) (4.65.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Logistic Regression model- 1\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wARGtO4ZCRdD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess the data\n",
        "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
        "X = vectorizer.fit_transform(df[\"utterance\"])\n",
        "y = df[\"intent\"]\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "clf = LogisticRegression(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "res.append('LR1')\n",
        "acc.append(accuracy)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYhepLH2yJO5",
        "outputId": "368ec2e0-6f04-43d0-f02b-151e73436076"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.92\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#NaiveBayes Classifier model - 2"
      ],
      "metadata": {
        "id": "v8YEHtL4CX3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/PacktPublishing/Mastering-spaCy/main/Chapter06/data/atis_intents.csv')\n",
        "data.columns = ['intent', 'utterance']\n",
        "\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Define the function to preprocess the text\n",
        "def preprocess(text):\n",
        "    doc = nlp(text)\n",
        "    return [token.lemma_.lower() for token in doc if not token.is_stop and not token.is_punct]\n",
        "\n",
        "def bag_of_words(text):\n",
        "    words = preprocess(text)\n",
        "    return dict([(word, True) for word in words])\n",
        "\n",
        "train_set = [(bag_of_words(text), intent) for text, intent in zip(train_data['utterance'], train_data['intent'])]\n",
        "test_set = [(bag_of_words(text), intent) for text, intent in zip(test_data['utterance'], test_data['intent'])]\n",
        "\n",
        "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
        "\n",
        "\n",
        "y_pred = [classifier.classify(features) for features, _ in test_set]\n",
        "\n",
        "# Compute the accuracy\n",
        "accuracy = accuracy_score([intent for _, intent in test_set], y_pred)\n",
        "\n",
        "res.append('NB')\n",
        "acc.append(accuracy)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3aUazIRy9Xu",
        "outputId": "27a77194-211e-40e4-fd9b-17bbc113f64f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.47690763052208834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Machine Learning model SVC - 3"
      ],
      "metadata": {
        "id": "MkwVI8QXB0hx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load the data\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/PacktPublishing/Mastering-spaCy/main/Chapter06/data/atis_intents.csv')\n",
        "data.columns = ['intent','text']\n",
        "\n",
        "\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a TF-IDF vectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "\n",
        "X_train = vectorizer.fit_transform(train_data['text'])\n",
        "y_train = train_data['intent']\n",
        "\n",
        "\n",
        "X_test = vectorizer.transform(test_data['text'])\n",
        "y_test = test_data['intent']\n",
        "\n",
        "\n",
        "svm = SVC()\n",
        "\n",
        "# Define the hyperparameters to search over\n",
        "param_grid = {\n",
        "    'kernel': ['linear', 'rbf'],\n",
        "    'C': [0.1, 1, 10, 100]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(svm, param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "print('Best hyperparameters:', grid_search.best_params_)\n",
        "\n",
        "\n",
        "y_pred = grid_search.predict(X_test)\n",
        "report = classification_report(y_test, y_pred, zero_division=1)\n",
        "report1 = classification_report(y_test, y_pred, zero_division=1,output_dict=True)\n",
        "res.append('SVM')\n",
        "acc.append(report1['accuracy'])\n",
        "\n",
        "print(report)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSwsxwLq1dFK",
        "outputId": "9cbd5765-8e10-47ca-ee79-a7821a84fa6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/model_selection/_split.py:700: UserWarning:\n",
            "\n",
            "The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'C': 10, 'kernel': 'linear'}\n",
            "                               precision    recall  f1-score   support\n",
            "\n",
            "            atis_abbreviation       1.00      0.93      0.96        29\n",
            "                atis_aircraft       0.86      0.92      0.89        13\n",
            "                 atis_airfare       0.90      0.90      0.90        84\n",
            "atis_airfare#atis_flight_time       1.00      0.00      0.00         1\n",
            "                 atis_airline       0.88      0.92      0.90        25\n",
            "  atis_airline#atis_flight_no       1.00      0.00      0.00         1\n",
            "                 atis_airport       1.00      1.00      1.00         3\n",
            "                atis_capacity       0.00      0.00      0.00         2\n",
            "                    atis_city       1.00      0.50      0.67         4\n",
            "                atis_distance       1.00      1.00      1.00         3\n",
            "                  atis_flight       0.98      0.98      0.98       745\n",
            "     atis_flight#atis_airfare       0.50      0.33      0.40         3\n",
            "               atis_flight_no       0.00      1.00      0.00         0\n",
            "             atis_flight_time       0.76      0.93      0.84        14\n",
            "             atis_ground_fare       1.00      0.67      0.80         3\n",
            "          atis_ground_service       0.96      0.93      0.95        58\n",
            "                atis_quantity       0.71      0.83      0.77         6\n",
            "             atis_restriction       0.33      0.50      0.40         2\n",
            "\n",
            "                     accuracy                           0.96       996\n",
            "                    macro avg       0.77      0.69      0.64       996\n",
            "                 weighted avg       0.96      0.96      0.96       996\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Rule Based model on top 8 inetents -4\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "U9WAqGn8Bhs-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def classify_intent(text):\n",
        "    # Define patterns for each intent\n",
        "    patterns = {\n",
        "    \"atis_flight\": r\"\\b(flight|flight number|flight numbers|depart|departure|arrive|arrival)\\b\",\n",
        "    \"atis_airfare\": r\"\\b(fare|price|cost)\\b\",\n",
        "    \"atis_ground_service\": r\"\\b(rental car|car rental|rent car|shuttle|taxi|cab|limousine|limo)\\b\",\n",
        "    \"atis_airline\": r\"\\b(airline|airlines|flight carrier)\\b\",\n",
        "    \"atis_abbreviation\": r\"\\b(abbr|abbreviate|abbreviation)\\b\",\n",
        "    \"atis_aircraft\": r\"\\b(aircraft|plane)\\b\",\n",
        "    \"atis_flight_time\": r\"\\b(arrival time|departure time|time|duration|length)\\b\",\n",
        "    \"atis_quantity\": r\"\\b(how many|how much)\\b\"\n",
        "      }\n",
        "\n",
        "\n",
        "\n",
        "    # Check if text matches any of the patterns\n",
        "    for intent, pattern in patterns.items():\n",
        "        if re.search(pattern, text, re.IGNORECASE):\n",
        "            return intent\n",
        "\n",
        "    # If no pattern is matched, return None\n",
        "    return \"unknown\"\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/PacktPublishing/Mastering-spaCy/main/Chapter06/data/atis_intents.csv')\n",
        "data.columns = [\"intent\", \"text\"]\n",
        "\n",
        "# Filter the dataset based on specific intent labels\n",
        "intent_labels = ['atis_flight', 'atis_airfare', 'atis_ground_service', 'atis_airline',\n",
        "               'atis_abbreviation', 'atis_aircraft', 'atis_flight_time', 'atis_quantity']\n",
        "df = data[data['intent'].isin(intent_labels)]\n",
        "\n",
        "# Apply the rule-based model to each text in the dataset and store the predictions\n",
        "predictions = []\n",
        "for text in df['text']:\n",
        "    intent = classify_intent(text)\n",
        "    predictions.append(intent)\n",
        "\n",
        "# Filter the predictions based on the same intent labels we used to filter the df\n",
        "filtered_predictions = [p if p in intent_labels else \"unknown\" for p in predictions]\n",
        "\n",
        "# Print the classification report\n",
        "\n",
        "report = classification_report(df['intent'], filtered_predictions, zero_division=1,output_dict=True)\n",
        "report1 = classification_report(df['intent'], filtered_predictions, zero_division=1)\n",
        "res.append('RBM-1')\n",
        "acc.append(report['accuracy'])\n",
        "print(report1)\n",
        "print(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYkzMDGk-mxM",
        "outputId": "626a833d-bb62-4b04-c0c9-ade2c5f341d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     precision    recall  f1-score   support\n",
            "\n",
            "  atis_abbreviation       1.00      0.03      0.07       147\n",
            "      atis_aircraft       0.94      0.58      0.72        81\n",
            "       atis_airfare       0.69      0.45      0.54       423\n",
            "       atis_airline       0.39      0.92      0.55       157\n",
            "        atis_flight       0.92      0.32      0.47      3665\n",
            "   atis_flight_time       0.29      0.07      0.12        54\n",
            "atis_ground_service       1.00      0.07      0.13       255\n",
            "      atis_quantity       0.83      0.57      0.67        51\n",
            "            unknown       0.00      1.00      0.00         0\n",
            "\n",
            "           accuracy                           0.33      4833\n",
            "          macro avg       0.67      0.45      0.36      4833\n",
            "       weighted avg       0.88      0.33      0.45      4833\n",
            "\n",
            "[0.9186746987951807, 0.47690763052208834, 0.33167804676184565]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rule Based model on complete dataset -5"
      ],
      "metadata": {
        "id": "_eMjY4zUBTqa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import spacy\n",
        "from spacy.matcher import Matcher\n",
        "\n",
        "# Load the dataset and rename columns\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/PacktPublishing/Mastering-spaCy/main/Chapter06/data/atis_intents.csv\")\n",
        "df.columns = [\"intent\", \"utterance\"]\n",
        "\n",
        "# Load the English language model in spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Define the rules for the different intents\n",
        "rules = {\n",
        "    \"atis_flight\": [{\"LOWER\": \"flight\"}],\n",
        "    \"atis_flight_time\": [{\"LOWER\": \"flight\"}, {\"LOWER\": \"time\"}],\n",
        "    \"atis_airfare\": [{\"LOWER\": \"airfare\"}],\n",
        "    \"atis_aircraft\": [{\"LOWER\": \"aircraft\"}],\n",
        "    \"atis_ground_service\": [{\"LOWER\": \"ground\"}, {\"LOWER\": \"service\"}],\n",
        "    \"atis_airport\": [{\"LOWER\": \"airport\"}],\n",
        "    \"atis_airline\": [{\"LOWER\": \"airline\"}],\n",
        "    \"atis_distance\": [{\"LOWER\": \"distance\"}],\n",
        "    \"atis_abbreviation\": [{\"LOWER\": \"abbreviation\"}],\n",
        "    \"atis_ground_fare\": [{\"LOWER\": \"ground\"}, {\"LOWER\": \"fare\"}],\n",
        "    \"atis_quantity\": [{\"LOWER\": \"quantity\"}],\n",
        "    \"atis_city\": [{\"LOWER\": \"city\"}],\n",
        "    \"atis_flight_no\": [{\"LOWER\": \"flight\"}, {\"LOWER\": \"number\"}],\n",
        "    \"atis_meal\": [{\"LOWER\": \"meal\"}],\n",
        "    \"atis_restriction\": [{\"LOWER\": \"restriction\"}],\n",
        "    \"atis_cheapest\": [{\"LOWER\": \"cheapest\"}],\n",
        "    \"atis_airline#atis_flight_no\": [{\"LOWER\": \"airline\"}, {\"LOWER\": \"flight\"}, {\"LOWER\": \"number\"}],\n",
        "    \"atis_airfare#atis_flight_time\": [{\"LOWER\": \"airfare\"}, {\"LOWER\": \"flight\"}, {\"LOWER\": \"time\"}],\n",
        "    \"atis_ground_service#atis_ground_fare\": [{\"LOWER\": \"ground\"}, {\"LOWER\": \"service\"}, {\"LOWER\": \"fare\"}],\n",
        "    \"atis_flight#atis_airfare\": [{\"LOWER\": \"flight\"}, {\"LOWER\": \"airfare\"}],\n",
        "    \"atis_capacity\": [{\"LOWER\": \"capacity\"}],\n",
        "}\n",
        "\n",
        "# Initialize the matcher with the shared vocabulary\n",
        "matcher = Matcher(nlp.vocab)\n",
        "\n",
        "# Add the rules to the matcher\n",
        "for intent, rule in rules.items():\n",
        "    matcher.add(intent, [rule])\n",
        "\n",
        "# Define a function to classify the intents\n",
        "def classify_intent(text):\n",
        "    doc = nlp(text.lower())\n",
        "    matches = matcher(doc)\n",
        "    if matches:\n",
        "        match_id, start, end = matches[0]\n",
        "        return nlp.vocab.strings[match_id]\n",
        "    else:\n",
        "        return \"unknown\"\n",
        "\n",
        "# Test the classifier on the dataset\n",
        "correct = 0\n",
        "total = 0\n",
        "for i, row in df.iterrows():\n",
        "    intent = row[\"intent\"]\n",
        "    utterance = row[\"utterance\"]\n",
        "    predicted_intent = classify_intent(utterance)\n",
        "    if predicted_intent == intent:\n",
        "        correct += 1\n",
        "    total += 1\n",
        "\n",
        "accuracy = correct / total\n",
        "res.append('RBM-2')\n",
        "acc.append(accuracy)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMS45R-wIWI8",
        "outputId": "5751ff91-208d-49ca-a972-e602213b5b91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.21780188868796463\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network - 6"
      ],
      "metadata": {
        "id": "tNyw3acJDSvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/PacktPublishing/Mastering-spaCy/main/Chapter06/data/atis_intents.csv')\n",
        "\n",
        "data.columns = [\"intent\", \"text\"]\n",
        "\n",
        "\n",
        "data = data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Split the data into training and test sets\n",
        "train_data = data[:int(0.8 * len(data))]\n",
        "test_data = data[int(0.8 * len(data)):]\n",
        "\n",
        "# Tokenize the text data\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(train_data['text'])\n",
        "train_sequences = tokenizer.texts_to_sequences(train_data['text'])\n",
        "test_sequences = tokenizer.texts_to_sequences(test_data['text'])\n",
        "\n",
        "# Pad the sequences to a fixed length\n",
        "max_length = max([len(seq) for seq in train_sequences + test_sequences])\n",
        "train_sequences = tf.keras.preprocessing.sequence.pad_sequences(train_sequences, maxlen=max_length)\n",
        "test_sequences = tf.keras.preprocessing.sequence.pad_sequences(test_sequences, maxlen=max_length)\n",
        "\n",
        "# one-hot encoded vectors\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(data['intent'])\n",
        "train_labels = tf.keras.utils.to_categorical(label_encoder.transform(train_data['intent']))\n",
        "test_labels = tf.keras.utils.to_categorical(label_encoder.transform(test_data['intent']))\n",
        "\n",
        "# model architecture\n",
        "inputs = Input(shape=(max_length,))\n",
        "x = Dense(128, activation='relu')(inputs)\n",
        "x = Dense(64, activation='relu')(x)\n",
        "outputs = Dense(len(label_encoder.classes_), activation='softmax')(x)\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(train_sequences, train_labels, epochs=10, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(test_sequences, test_labels)\n",
        "res.append('NN1')\n",
        "acc.append(accuracy)\n",
        "print('Test loss: {:.2f}'.format(loss))\n",
        "print('Test accuracy: {:.2f}'.format(accuracy))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujjKqYp5Kjr9",
        "outputId": "bbd06342-fd96-4d19-ed05-126935db9a24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "100/100 [==============================] - 4s 13ms/step - loss: 8.1559 - accuracy: 0.5358 - val_loss: 4.3424 - val_accuracy: 0.6688\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 2.6594 - accuracy: 0.6621 - val_loss: 3.0662 - val_accuracy: 0.6474\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.9407 - accuracy: 0.6913 - val_loss: 2.6676 - val_accuracy: 0.7102\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 1.5904 - accuracy: 0.7177 - val_loss: 2.4346 - val_accuracy: 0.7139\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 1s 6ms/step - loss: 1.3496 - accuracy: 0.7421 - val_loss: 2.3378 - val_accuracy: 0.6713\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 1.2428 - accuracy: 0.7544 - val_loss: 2.2763 - val_accuracy: 0.6989\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 1s 10ms/step - loss: 1.1481 - accuracy: 0.7585 - val_loss: 2.2286 - val_accuracy: 0.7127\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 1.0707 - accuracy: 0.7676 - val_loss: 2.1690 - val_accuracy: 0.7064\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 1s 8ms/step - loss: 0.9945 - accuracy: 0.7783 - val_loss: 2.1877 - val_accuracy: 0.7227\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 1s 11ms/step - loss: 0.9362 - accuracy: 0.7823 - val_loss: 2.2706 - val_accuracy: 0.7139\n",
            "32/32 [==============================] - 0s 5ms/step - loss: 2.2674 - accuracy: 0.6948\n",
            "Test loss: 2.27\n",
            "Test accuracy: 0.69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network - 7"
      ],
      "metadata": {
        "id": "z6bDXq0NDY29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/PacktPublishing/Mastering-spaCy/main/Chapter06/data/atis_intents.csv')\n",
        "\n",
        "data.columns = [\"intent\", \"text\"]\n",
        "\n",
        "\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "train_labels = set(train_data['intent'])\n",
        "test_labels = set(test_data['intent'])\n",
        "common_labels = train_labels.intersection(test_labels)\n",
        "\n",
        "train_data = train_data[train_data['intent'].isin(common_labels)]\n",
        "test_data = test_data[test_data['intent'].isin(common_labels)]\n",
        "# Tokenize\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_data['text'])\n",
        "\n",
        "train_sequences = tokenizer.texts_to_sequences(train_data['text'])\n",
        "test_sequences = tokenizer.texts_to_sequences(test_data['text'])\n",
        "\n",
        "# Pading\n",
        "maxlen = 50\n",
        "train_sequences = pad_sequences(train_sequences, padding='post', maxlen=maxlen)\n",
        "test_sequences = pad_sequences(test_sequences, padding='post', maxlen=maxlen)\n",
        "\n",
        "# one-hot encoded vectors\n",
        "label_encoder = tf.keras.utils.to_categorical(train_data['intent'].factorize()[0])\n",
        "num_classes = label_encoder.shape[1]\n",
        "\n",
        "# model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=50, input_length=maxlen),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Conv1D(128, 5, activation='relu'),\n",
        "    tf.keras.layers.GlobalMaxPooling1D(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "model.summary()\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model.fit(train_sequences, label_encoder, epochs=20, batch_size=64)\n",
        "\n",
        "# Evaluate the model on test data\n",
        "test_label_encoder = tf.keras.utils.to_categorical(test_data['intent'].factorize()[0])\n",
        "loss, accuracy = model.evaluate(test_sequences, test_label_encoder, verbose=0)\n",
        "res.append('NN2')\n",
        "acc.append(accuracy)\n",
        "print('Test loss: {:.2f}'.format(loss))\n",
        "print('Test accuracy: {:.2f}'.format(accuracy))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-jXedV9f_r7",
        "outputId": "7fbcef9a-e9fc-48cb-d769-07044c917a59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_12 (Embedding)    (None, 50, 50)            42150     \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 50, 50)            0         \n",
            "                                                                 \n",
            " conv1d_4 (Conv1D)           (None, 46, 128)           32128     \n",
            "                                                                 \n",
            " global_max_pooling1d_4 (Glo  (None, 128)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 16)                2064      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 92,854\n",
            "Trainable params: 92,854\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "62/62 [==============================] - 5s 45ms/step - loss: 1.4914 - accuracy: 0.7101\n",
            "Epoch 2/20\n",
            "62/62 [==============================] - 3s 44ms/step - loss: 0.9967 - accuracy: 0.7386\n",
            "Epoch 3/20\n",
            "62/62 [==============================] - 4s 57ms/step - loss: 0.7645 - accuracy: 0.7965\n",
            "Epoch 4/20\n",
            "62/62 [==============================] - 4s 60ms/step - loss: 0.6199 - accuracy: 0.8452\n",
            "Epoch 5/20\n",
            "62/62 [==============================] - 3s 43ms/step - loss: 0.4644 - accuracy: 0.8801\n",
            "Epoch 6/20\n",
            "62/62 [==============================] - 3s 45ms/step - loss: 0.3664 - accuracy: 0.8960\n",
            "Epoch 7/20\n",
            "62/62 [==============================] - 2s 40ms/step - loss: 0.3010 - accuracy: 0.9146\n",
            "Epoch 8/20\n",
            "62/62 [==============================] - 3s 50ms/step - loss: 0.2602 - accuracy: 0.9250\n",
            "Epoch 9/20\n",
            "62/62 [==============================] - 4s 63ms/step - loss: 0.2155 - accuracy: 0.9384\n",
            "Epoch 10/20\n",
            "62/62 [==============================] - 3s 48ms/step - loss: 0.1836 - accuracy: 0.9477\n",
            "Epoch 11/20\n",
            "62/62 [==============================] - 3s 51ms/step - loss: 0.1631 - accuracy: 0.9540\n",
            "Epoch 12/20\n",
            "62/62 [==============================] - 5s 87ms/step - loss: 0.1469 - accuracy: 0.9563\n",
            "Epoch 13/20\n",
            "62/62 [==============================] - 3s 52ms/step - loss: 0.1314 - accuracy: 0.9596\n",
            "Epoch 14/20\n",
            "62/62 [==============================] - 3s 41ms/step - loss: 0.1282 - accuracy: 0.9606\n",
            "Epoch 15/20\n",
            "62/62 [==============================] - 3s 53ms/step - loss: 0.1140 - accuracy: 0.9705\n",
            "Epoch 16/20\n",
            "62/62 [==============================] - 4s 57ms/step - loss: 0.0995 - accuracy: 0.9717\n",
            "Epoch 17/20\n",
            "62/62 [==============================] - 3s 45ms/step - loss: 0.0945 - accuracy: 0.9735\n",
            "Epoch 18/20\n",
            "62/62 [==============================] - 2s 26ms/step - loss: 0.0863 - accuracy: 0.9773\n",
            "Epoch 19/20\n",
            "62/62 [==============================] - 2s 26ms/step - loss: 0.0825 - accuracy: 0.9755\n",
            "Epoch 20/20\n",
            "62/62 [==============================] - 2s 37ms/step - loss: 0.0729 - accuracy: 0.9798\n",
            "Test loss: 3.54\n",
            "Test accuracy: 0.74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network - 8"
      ],
      "metadata": {
        "id": "l4R6_qYFDakO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, GlobalAveragePooling1D, Dense\n",
        "\n",
        "\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/PacktPublishing/Mastering-spaCy/main/Chapter06/data/atis_intents.csv')\n",
        "\n",
        "data.columns = [\"intent\", \"text\"]\n",
        "\n",
        "\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "train_labels = set(train_data['intent'])\n",
        "test_labels = set(test_data['intent'])\n",
        "\n",
        "\n",
        "common_labels = train_labels.intersection(test_labels)\n",
        "\n",
        "# Check if there are any common labels\n",
        "if not common_labels:\n",
        "    print('No common labels between train and test sets')\n",
        "    exit()\n",
        "\n",
        "# Filter the train and test sets to only include instances with common labels\n",
        "train_intents = train_data[train_data['intent'].isin(common_labels)]\n",
        "test_intents = test_data[test_data['intent'].isin(common_labels)]\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(train_intents['intent'])\n",
        "train_labels = label_encoder.transform(train_intents['intent'])\n",
        "test_labels = label_encoder.transform(test_intents['intent'])\n",
        "\n",
        "#one-hot encoded vectors\n",
        "num_classes = len(common_labels)\n",
        "train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
        "test_labels = to_categorical(test_labels, num_classes=num_classes)\n",
        "\n",
        "# Tokenize\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_intents['text'])\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "tokenizer = Tokenizer(num_words=vocab_size, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(train_intents['text'])\n",
        "maxlen = 100\n",
        "trunc_type='post'\n",
        "padding_type='post'\n",
        "embedding_dim = 100\n",
        "validation_split = 0.1\n",
        "\n",
        "train_sequences = tokenizer.texts_to_sequences(train_intents['text'])\n",
        "train_sequences = pad_sequences(train_sequences, maxlen=maxlen, truncating=trunc_type, padding=padding_type)\n",
        "test_sequences = tokenizer.texts_to_sequences(test_intents['text'])\n",
        "test_sequences = pad_sequences(test_sequences, maxlen=maxlen, truncating=trunc_type, padding=padding_type)\n",
        "\n",
        "# Build model\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, embedding_dim, input_length=maxlen),\n",
        "    GlobalAveragePooling1D(),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "model.summary()\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "history = model.fit(train_sequences, train_labels, epochs=20, validation_split=validation_split, verbose=1)\n",
        "\n",
        "# Evaluate model on test data\n",
        "loss, accuracy = model.evaluate(test_sequences, test_labels, verbose=0)\n",
        "res.append('NN3')\n",
        "acc.append(accuracy)\n",
        "print('Test loss:', loss)\n",
        "print('Test accuracy:', accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQta8iTljLd1",
        "outputId": "2cf58e13-1d2e-453b-b9f5-615a33d77f72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_13 (Embedding)    (None, 100, 100)          84300     \n",
            "                                                                 \n",
            " global_average_pooling1d_5   (None, 100)              0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 16)                1616      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 85,916\n",
            "Trainable params: 85,916\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "112/112 [==============================] - 3s 14ms/step - loss: 1.9818 - accuracy: 0.7166 - val_loss: 1.2048 - val_accuracy: 0.7424\n",
            "Epoch 2/20\n",
            "112/112 [==============================] - 1s 11ms/step - loss: 1.1242 - accuracy: 0.7368 - val_loss: 1.1073 - val_accuracy: 0.7424\n",
            "Epoch 3/20\n",
            "112/112 [==============================] - 1s 9ms/step - loss: 1.0805 - accuracy: 0.7368 - val_loss: 1.0785 - val_accuracy: 0.7424\n",
            "Epoch 4/20\n",
            "112/112 [==============================] - 1s 10ms/step - loss: 1.0557 - accuracy: 0.7368 - val_loss: 1.0579 - val_accuracy: 0.7424\n",
            "Epoch 5/20\n",
            "112/112 [==============================] - 1s 10ms/step - loss: 1.0307 - accuracy: 0.7368 - val_loss: 1.0249 - val_accuracy: 0.7424\n",
            "Epoch 6/20\n",
            "112/112 [==============================] - 1s 10ms/step - loss: 1.0001 - accuracy: 0.7368 - val_loss: 0.9912 - val_accuracy: 0.7424\n",
            "Epoch 7/20\n",
            "112/112 [==============================] - 2s 14ms/step - loss: 0.9630 - accuracy: 0.7368 - val_loss: 0.9517 - val_accuracy: 0.7424\n",
            "Epoch 8/20\n",
            "112/112 [==============================] - 3s 23ms/step - loss: 0.9209 - accuracy: 0.7368 - val_loss: 0.9087 - val_accuracy: 0.7424\n",
            "Epoch 9/20\n",
            "112/112 [==============================] - 1s 9ms/step - loss: 0.8774 - accuracy: 0.7385 - val_loss: 0.8669 - val_accuracy: 0.7449\n",
            "Epoch 10/20\n",
            "112/112 [==============================] - 1s 10ms/step - loss: 0.8352 - accuracy: 0.7447 - val_loss: 0.8280 - val_accuracy: 0.7500\n",
            "Epoch 11/20\n",
            "112/112 [==============================] - 1s 9ms/step - loss: 0.7952 - accuracy: 0.7584 - val_loss: 0.7888 - val_accuracy: 0.7601\n",
            "Epoch 12/20\n",
            "112/112 [==============================] - 1s 10ms/step - loss: 0.7576 - accuracy: 0.7727 - val_loss: 0.7555 - val_accuracy: 0.7677\n",
            "Epoch 13/20\n",
            "112/112 [==============================] - 1s 10ms/step - loss: 0.7242 - accuracy: 0.7854 - val_loss: 0.7233 - val_accuracy: 0.7854\n",
            "Epoch 14/20\n",
            "112/112 [==============================] - 1s 11ms/step - loss: 0.6911 - accuracy: 0.8005 - val_loss: 0.6945 - val_accuracy: 0.8030\n",
            "Epoch 15/20\n",
            "112/112 [==============================] - 1s 10ms/step - loss: 0.6610 - accuracy: 0.8199 - val_loss: 0.6700 - val_accuracy: 0.8283\n",
            "Epoch 16/20\n",
            "112/112 [==============================] - 1s 10ms/step - loss: 0.6342 - accuracy: 0.8294 - val_loss: 0.6409 - val_accuracy: 0.8510\n",
            "Epoch 17/20\n",
            "112/112 [==============================] - 1s 10ms/step - loss: 0.6078 - accuracy: 0.8443 - val_loss: 0.6184 - val_accuracy: 0.8510\n",
            "Epoch 18/20\n",
            "112/112 [==============================] - 1s 13ms/step - loss: 0.5839 - accuracy: 0.8493 - val_loss: 0.5965 - val_accuracy: 0.8586\n",
            "Epoch 19/20\n",
            "112/112 [==============================] - 2s 14ms/step - loss: 0.5608 - accuracy: 0.8555 - val_loss: 0.5745 - val_accuracy: 0.8611\n",
            "Epoch 20/20\n",
            "112/112 [==============================] - 1s 8ms/step - loss: 0.5407 - accuracy: 0.8634 - val_loss: 0.5544 - val_accuracy: 0.8611\n",
            "Test loss: 0.5246026515960693\n",
            "Test accuracy: 0.8753768801689148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network - 9"
      ],
      "metadata": {
        "id": "DBnQPr5FDcZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/PacktPublishing/Mastering-spaCy/main/Chapter06/data/atis_intents.csv')\n",
        "\n",
        "data.columns = [\"intent\", \"text\"]\n",
        "\n",
        "\n",
        "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
        "\n",
        "train_labels = set(train_data['intent'])\n",
        "test_labels = set(test_data['intent'])\n",
        "common_labels = train_labels.intersection(test_labels)\n",
        "\n",
        "train_df = train_data[train_data['intent'].isin(common_labels)]\n",
        "test_df = test_data[test_data['intent'].isin(common_labels)]\n",
        "\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "train_labels = label_encoder.fit_transform(train_df['intent'])\n",
        "test_labels = label_encoder.transform(test_df['intent'])\n",
        "\n",
        "num_classes = len(np.unique(train_labels))\n",
        "train_labels = to_categorical(train_labels, num_classes)\n",
        "test_labels = to_categorical(test_labels, num_classes)\n",
        "\n",
        "# Tokenize text\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(train_df['text'])\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "train_sequences = tokenizer.texts_to_sequences(train_df['text'])\n",
        "test_sequences = tokenizer.texts_to_sequences(test_df['text'])\n",
        "\n",
        "# Pad sequences\n",
        "maxlen = max([len(x) for x in train_sequences])\n",
        "train_sequences = tf.keras.preprocessing.sequence.pad_sequences(train_sequences, maxlen=maxlen, padding='post')\n",
        "test_sequences = tf.keras.preprocessing.sequence.pad_sequences(test_sequences, maxlen=maxlen, padding='post')\n",
        "\n",
        "\n",
        "# model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, 16, input_length=maxlen),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_sequences, train_labels, epochs=10, validation_split=0.2, verbose=1)\n",
        "\n",
        "\n",
        "# Evaluate model on test data\n",
        "test_loss, test_acc = model.evaluate(test_sequences, test_labels, verbose=1)\n",
        "res.append('NN4')\n",
        "acc.append(test_acc)\n",
        "print('Test Loss:', test_loss)\n",
        "print('Test Accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-I2-K6Ak58C",
        "outputId": "c62c6486-c301-4e34-ed72-2159ffbc517a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "99/99 [==============================] - 1s 6ms/step - loss: 1.4432 - accuracy: 0.7219 - val_loss: 1.0689 - val_accuracy: 0.7184\n",
            "Epoch 2/10\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.9259 - accuracy: 0.7465 - val_loss: 0.7966 - val_accuracy: 0.7311\n",
            "Epoch 3/10\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.7202 - accuracy: 0.7891 - val_loss: 0.6824 - val_accuracy: 0.8081\n",
            "Epoch 4/10\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.6056 - accuracy: 0.8280 - val_loss: 0.6010 - val_accuracy: 0.8460\n",
            "Epoch 5/10\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.5355 - accuracy: 0.8539 - val_loss: 0.5109 - val_accuracy: 0.8838\n",
            "Epoch 6/10\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.4558 - accuracy: 0.8835 - val_loss: 0.4429 - val_accuracy: 0.8939\n",
            "Epoch 7/10\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.3679 - accuracy: 0.9078 - val_loss: 0.3536 - val_accuracy: 0.9154\n",
            "Epoch 8/10\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.2822 - accuracy: 0.9312 - val_loss: 0.3065 - val_accuracy: 0.9217\n",
            "Epoch 9/10\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.2354 - accuracy: 0.9400 - val_loss: 0.2770 - val_accuracy: 0.9268\n",
            "Epoch 10/10\n",
            "99/99 [==============================] - 0s 4ms/step - loss: 0.2035 - accuracy: 0.9460 - val_loss: 0.2488 - val_accuracy: 0.9343\n",
            "32/32 [==============================] - 0s 2ms/step - loss: 0.1910 - accuracy: 0.9437\n",
            "Test Loss: 0.19097554683685303\n",
            "Test Accuracy: 0.9437186121940613\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Comparision"
      ],
      "metadata": {
        "id": "_63Amv25PkkA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "dKes6pDMGqRH",
        "outputId": "c8007b4d-e9c1-4d53-fbfd-25c2f1585515"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   model  accuracy\n",
              "0    LR1  0.918675\n",
              "1     NB  0.476908\n",
              "2  RBM-1  0.331678\n",
              "3  RBM-2  0.217802\n",
              "4    NN1  0.694779\n",
              "5    NN2  0.736683\n",
              "6    NN3  0.875377\n",
              "7    NN4  0.943719"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4efeff28-086f-4c24-9123-178a9878ee14\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LR1</td>\n",
              "      <td>0.918675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NB</td>\n",
              "      <td>0.476908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RBM-1</td>\n",
              "      <td>0.331678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RBM-2</td>\n",
              "      <td>0.217802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NN1</td>\n",
              "      <td>0.694779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NN2</td>\n",
              "      <td>0.736683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>NN3</td>\n",
              "      <td>0.875377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>NN4</td>\n",
              "      <td>0.943719</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4efeff28-086f-4c24-9123-178a9878ee14')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4efeff28-086f-4c24-9123-178a9878ee14 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4efeff28-086f-4c24-9123-178a9878ee14');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dzXCoeOuSQbp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}